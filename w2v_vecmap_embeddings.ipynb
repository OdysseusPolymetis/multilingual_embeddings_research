{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>VecMap multilingual embeddings using W2V vectorizer</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation for VecMap multilingual embeddings using GloVe. References here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import glob\n",
    "import string\n",
    "import unidecode\n",
    "import csv\n",
    "from lxml import etree as ET\n",
    "import lxml.html\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des listes de phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory containing XML tagged files, Perseus way\n",
    "author_gk=\"./xml/homer_gk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory containing French XML tagged files, home made way\n",
    "author_fr = \"./xml/fr_translators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_gk=\"\"\n",
    "lemmatized_sentences_gk=list()\n",
    "files= glob.iglob(author_gk+'/**/*.xml', recursive=True)\n",
    "for filename in files :\n",
    "    p = ET.XMLParser(remove_blank_text=True, resolve_entities=False)\n",
    "    tree_gk = ET.parse(filename,p)\n",
    "    sentences_gk = tree_gk.findall(\".//sentence\")\n",
    "    for sentence in sentences_gk:\n",
    "        words_per_sentence=list()\n",
    "        for word in sentence.xpath(\".//word/@lemma\"):\n",
    "            words_per_sentence.append(word)\n",
    "        lemmatized_sentences_gk.append(words_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_fr=\"\"\n",
    "list_of_vocs={}\n",
    "lemmatized_sentences_fr=list()\n",
    "files= glob.iglob(author_fr+'/**/*.xml', recursive=True)\n",
    "for filename in files :\n",
    "    p = ET.XMLParser(remove_blank_text=True, resolve_entities=False)\n",
    "    tree_fr = ET.parse(filename,p)\n",
    "    author=filename[len(author_fr)+1:len(filename)-11]\n",
    "    sentences_fr = tree_fr.findall(\".//sentence\")\n",
    "    for sentence in sentences_fr:\n",
    "        words_per_sentence = list()\n",
    "        for word in sentence.xpath(\".//word/@lemma\"):\n",
    "            if word not in string.punctuation and word is not \" \":\n",
    "                words_per_sentence.append(word)\n",
    "                if word in list_of_vocs.keys():\n",
    "                    list_of_vocs[word].add(author)\n",
    "                else :\n",
    "                    list_of_vocs[word]=set()\n",
    "                    list_of_vocs[word].add(author)\n",
    "        lemmatized_sentences_fr.append(words_per_sentence)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking sentences</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἀνήρ', 'ἐγώ', 'ἐνέπω', ',', 'Μοῦσα', ',', 'πολύτροπος', ',', 'ὅς', 'μάλα', 'πολύς', 'πλάζω', ',', 'ἐπεί', 'Τροία', 'ἱερός', 'πτολίεθρον', 'πέρθω', '·']\n",
      "15138\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_sentences_gk[0])\n",
    "print(len(lemmatized_sentences_gk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ce', 'être', 'ainsi', 'que', 'en', 'ces', 'lieu', 'prier', 'le', 'noble', 'et', 'patient', 'Ulysse', 'cependant', 'le', 'jeune', 'fille', 'sur', 'le', 'chariot', 'que', 'traîner', 'de', 'fort', 'mule', 'arriver', 'à', 'le', 'ville']\n",
      "120154\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_sentences_fr[0])\n",
    "print(len(lemmatized_sentences_fr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training W2V models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_comp=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gk = Word2Vec(lemmatized_sentences_gk, min_count=10,max_vocab_size=10000, negative=5, iter=50, size=nb_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gk.wv.save_word2vec_format(\"./dumped/w2v_model_gk.emb\", fvocab=None, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fr = Word2Vec(lemmatized_sentences_fr, min_count=10,max_vocab_size=10000, negative=5, iter=50, size=nb_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fr.wv.save_word2vec_format(\"./dumped/w2v_model_fr.emb\", fvocab=None, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ὑφορβός', 0.4769396185874939),\n",
       " ('Εὔμαιος', 0.34372854232788086),\n",
       " ('ἀοιδός', 0.33389297127723694),\n",
       " ('Ἀχιλλεύς', 0.3271576166152954),\n",
       " ('Ἀγήνωρ', 0.307390034198761),\n",
       " ('Λακεδαίμων', 0.28493624925613403),\n",
       " ('γυνή', 0.28086012601852417),\n",
       " ('ξενίζω', 0.2763843238353729),\n",
       " ('Ὀρέστης', 0.2703791856765747),\n",
       " ('Μενοιτιάδης', 0.2694649398326874)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gk.wv.most_similar('Ὀδυσσεύς')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Odysseus', 0.6022398471832275),\n",
       " ('Télémaque', 0.4212080240249634),\n",
       " ('héros', 0.4194243550300598),\n",
       " ('Pirée', 0.3815237879753113),\n",
       " ('Pénélope', 0.3777717351913452),\n",
       " ('Théoclymène', 0.36129456758499146),\n",
       " ('Oreste', 0.34781932830810547),\n",
       " ('Alcinoos', 0.3445066213607788),\n",
       " ('Alcinoüs', 0.3425518870353699),\n",
       " ('Philoctète', 0.3377434015274048)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fr.wv.most_similar('Ulysse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mapping with VecMap</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(source,target) :\n",
    "    subprocess.call(['python3', './vecmap/map_embeddings.py', '--cuda','--semi_supervised', './dicts/train.dict', source,target, './dumped/src_vecmapped_w2v.emb', './dumped/trg_vecmapped_w2v.emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping('./dumped/w2v_model_gk.emb','./dumped/w2v_model_fr.emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Making KeyedVectors compatible models from VecMap models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_vec_file='./dumped/src_vecmapped_w2v.emb'\n",
    "fr_vec_file=\"./dumped/trg_vecmapped_w2v.emb\"\n",
    "with open ('./dumped/bilingual_w2v_vecs.txt','w+') as f_bil:\n",
    "    f_bil.write(str(len(model_gk.wv.vocab)+len(model_fr.wv.vocab))+\" \"+str(nb_comp)+\"\\n\")\n",
    "    glob=list()\n",
    "    with open(gk_vec_file, 'r') as f_gk:\n",
    "        glob.extend(f_gk.readlines()[1:])\n",
    "    with open(fr_vec_file,'r') as f_fr:\n",
    "        glob.extend(f_fr.readlines()[1:])\n",
    "    \n",
    "    for line in glob:\n",
    "        f_bil.write(line)\n",
    "    \n",
    "    f_bil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltsv = gensim.models.KeyedVectors.load_word2vec_format('./dumped/bilingual_w2v_vecs.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trépas', 0.7332578897476196),\n",
       " ('Parque', 0.6382513046264648),\n",
       " ('μάχη', 0.6073669195175171),\n",
       " ('Kèr', 0.5236033797264099),\n",
       " ('perte', 0.4916805922985077),\n",
       " ('malheur', 0.489699125289917),\n",
       " ('meurtre', 0.48224690556526184),\n",
       " ('destin', 0.4717833399772644),\n",
       " ('carnage', 0.4534017741680145),\n",
       " ('châtiment', 0.4489312171936035)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltsv.most_similar('mort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Writing metadata for TensorFlow Projector</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dumped/tensorflow_w2v.tsv\", 'w+') as tensors:\n",
    "    with open(\"./dumped/tensorflowmeta_w2v.tsv\", 'w+') as metadata:\n",
    "        for word in modeltsv.index2word:\n",
    "            metadata.write(word+'\\n')\n",
    "            vector_row = '\\t'.join(map(str, modeltsv[word]))\n",
    "            tensors.write(vector_row + '\\n')\n",
    "        metadata.close()\n",
    "    tensors.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>If you want to know which author used what</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dumped/tensorflow_w2v_names.tsv\", 'w+') as tensors:\n",
    "    with open(\"./dumped/tensorflowmeta_w2v_names.tsv\", 'w+') as metadata:\n",
    "         for word in modeltsv.index2word:\n",
    "                authors=\"\"\n",
    "                if word in list_of_vocs.keys():\n",
    "                    if len(list_of_vocs[word])<5:\n",
    "                        authors+=\"_\".join(list_of_vocs[word])\n",
    "                if (len(authors)>1):\n",
    "                    metadata.write(word+\"_\"+authors+'\\n')\n",
    "                else:\n",
    "                    metadata.write(word+'\\n')\n",
    "                vector_row = '\\t'.join(map(str, modeltsv[word]))\n",
    "                tensors.write(vector_row + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
