{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>VecMap multilingual embeddings using GloVe vectorizer</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation for VecMap multilingual embeddings using GloVe. References here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import glob\n",
    "import string\n",
    "import unidecode\n",
    "from glove import Corpus, Glove\n",
    "import csv\n",
    "from lxml import etree as ET\n",
    "import lxml.html\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des listes de phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory containing XML tagged files, Perseus way\n",
    "author_gk=\"./xml/homer_gk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory containing French XML tagged files, home made way\n",
    "author_fr = \"./xml/fr_translators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_gk=\"\"\n",
    "lemmatized_sentences_gk=list()\n",
    "files= glob.iglob(author_gk+'/**/*.xml', recursive=True)\n",
    "for filename in files :\n",
    "    p = ET.XMLParser(remove_blank_text=True, resolve_entities=False)\n",
    "    tree_gk = ET.parse(filename,p)\n",
    "    sentences_gk = tree_gk.findall(\".//sentence\")\n",
    "    for sentence in sentences_gk:\n",
    "        words_per_sentence=list()\n",
    "        for word in sentence.xpath(\".//word/@lemma\"):\n",
    "            words_per_sentence.append(word)\n",
    "        lemmatized_sentences_gk.append(words_per_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_fr=\"\"\n",
    "lemmatized_sentences_fr=list()\n",
    "files= glob.iglob(author_fr+'/**/*.xml', recursive=True)\n",
    "for filename in files :\n",
    "    p = ET.XMLParser(remove_blank_text=True, resolve_entities=False)\n",
    "    tree_fr = ET.parse(filename,p)\n",
    "    sentences_fr = tree_fr.findall(\".//sentence\")\n",
    "    for sentence in sentences_fr:\n",
    "        words_per_sentence = list()\n",
    "        for word in sentence.xpath(\".//word/@lemma\"):\n",
    "            if word not in string.punctuation and word is not \" \":\n",
    "                words_per_sentence.append(word)\n",
    "        lemmatized_sentences_fr.append(words_per_sentence)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking sentences</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ἀνήρ', 'ἐγώ', 'ἐνέπω', ',', 'Μοῦσα', ',', 'πολύτροπος', ',', 'ὅς', 'μάλα', 'πολύς', 'πλάζω', ',', 'ἐπεί', 'Τροία', 'ἱερός', 'πτολίεθρον', 'πέρθω', '·']\n",
      "15138\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_sentences_gk[0])\n",
    "print(len(lemmatized_sentences_gk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ce', 'être', 'ainsi', 'que', 'en', 'ces', 'lieu', 'prier', 'le', 'noble', 'et', 'patient', 'Ulysse', 'cependant', 'le', 'jeune', 'fille', 'sur', 'le', 'chariot', 'que', 'traîner', 'de', 'fort', 'mule', 'arriver', 'à', 'le', 'ville']\n",
      "120154\n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_sentences_fr[0])\n",
    "print(len(lemmatized_sentences_fr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training GloVe models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_comp=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_gk = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_gk.fit(lemmatized_sentences_gk, window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_gk = Glove(no_components=nb_comp, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glove_gk.fit(corpus_gk.matrix, epochs=150, no_threads=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_gk.add_dictionary(corpus_gk.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fr = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fr.fit(lemmatized_sentences_fr, window=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_fr = Glove(no_components=nb_comp, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glove_fr.fit(corpus_fr.matrix, epochs=150, no_threads=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_fr.add_dictionary(corpus_fr.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('πολύμητις', 0.5707263838148661),\n",
       " ('ταλασίφρων', 0.5467660868558205),\n",
       " ('πολυμήχανος', 0.5328508330360958),\n",
       " ('τλήμων', 0.5301694650317548)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_gk.most_similar('Ὀδυσσεύς')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Odysseus', 0.6425404979335774),\n",
       " ('ingénieux', 0.36945546442174043),\n",
       " ('patient', 0.3214320093424856),\n",
       " ('aviser', 0.30950651029393333)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_fr.most_similar('Ulysse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating VecMap compatible models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dumped/glove_vecs_gk.txt',  \"w+\") as glove_vecs_gk:\n",
    "    glove_vecs_gk.write(str(len(glove_gk.dictionary))+\" \"+str(nb_comp)+\"\\n\")\n",
    "    for idx_word, word in enumerate(glove_gk.dictionary):\n",
    "        glove_vecs_gk.write(word+\" \")\n",
    "        if idx_word<len(glove_gk.dictionary)-1:\n",
    "            for idx_stat, stat in enumerate(glove_gk.word_vectors[glove_gk.dictionary[word]]):\n",
    "                if idx_stat<len(glove_gk.word_vectors[glove_gk.dictionary[word]])-1:\n",
    "                    glove_vecs_gk.write(str(stat)+\" \")\n",
    "                else:\n",
    "                    glove_vecs_gk.write(str(stat))\n",
    "            glove_vecs_gk.write(\"\\n\")\n",
    "        else:\n",
    "            for idx_stat, stat in enumerate(glove_gk.word_vectors[glove_gk.dictionary[word]]):\n",
    "                if idx_stat<len(glove_gk.word_vectors[glove_gk.dictionary[word]])-1:\n",
    "                    glove_vecs_gk.write(str(stat)+\" \")\n",
    "                else:\n",
    "                    glove_vecs_gk.write(str(stat))\n",
    "            \n",
    "    glove_vecs_gk.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dumped/glove_vecs_fr.txt',  \"w+\") as glove_vecs_fr:\n",
    "    glove_vecs_fr.write(str(len(glove_fr.dictionary))+\" \"+str(nb_comp)+\"\\n\")\n",
    "    for idx_word, word in enumerate(corpus_fr.dictionary):\n",
    "        glove_vecs_fr.write(word+\" \")\n",
    "        if idx_word<len(glove_fr.dictionary)-1:\n",
    "            for idx_stat, stat in enumerate(glove_fr.word_vectors[glove_fr.dictionary[word]]):\n",
    "                if idx_stat<len(glove_fr.word_vectors[glove_fr.dictionary[word]])-1:\n",
    "                    glove_vecs_fr.write(str(stat)+\" \")\n",
    "                else:\n",
    "                    glove_vecs_fr.write(str(stat))\n",
    "            glove_vecs_fr.write(\"\\n\")\n",
    "        else:\n",
    "            for idx_stat, stat in enumerate(glove_fr.word_vectors[glove_fr.dictionary[word]]):\n",
    "                if idx_stat<len(glove_fr.word_vectors[glove_fr.dictionary[word]])-1:\n",
    "                    glove_vecs_fr.write(str(stat)+\" \")\n",
    "                else:\n",
    "                    glove_vecs_fr.write(str(stat))\n",
    "    glove_vecs_fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mapping with VecMap</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(source,target) :\n",
    "    subprocess.call(['python3', './vecmap/map_embeddings.py', '--cuda','--semi_supervised', './dicts/train.dict', source,target, './dumped/src_vecmapped_glove.emb', './dumped/trg_vecmapped_glove.emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping('./dumped/glove_vecs_gk.txt','./dumped/glove_vecs_fr.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Making KeyedVectors compatible models from VecMap models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_vec_file='./dumped/src_vecmapped_glove.emb'\n",
    "fr_vec_file=\"./dumped/trg_vecmapped_glove.emb\"\n",
    "with open ('./dumped/bilingual_glove_vecs.txt','w+') as f_bil:\n",
    "    f_bil.write(str(len(glove_fr.dictionary)+len(glove_gk.dictionary))+\" \"+str(nb_comp)+\"\\n\")\n",
    "    glob=list()\n",
    "    with open(gk_vec_file, 'r') as f_gk:\n",
    "        glob.extend(f_gk.readlines()[1:])\n",
    "    with open(fr_vec_file,'r') as f_fr:\n",
    "        glob.extend(f_fr.readlines()[1:])\n",
    "    \n",
    "    for line in glob:\n",
    "        f_bil.write(line)\n",
    "    \n",
    "    f_bil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltsv = gensim.models.KeyedVectors.load_word2vec_format('./dumped/bilingual_glove_vecs.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Odysseus', 0.874396562576294),\n",
       " ('ἀτάρ', 0.8216365575790405),\n",
       " ('revenir', 0.7921326756477356),\n",
       " ('alors', 0.7792285680770874),\n",
       " ('héros', 0.7757202982902527),\n",
       " ('père', 0.7735368609428406),\n",
       " ('πόθι', 0.77182537317276),\n",
       " ('ἐπεί', 0.766440212726593),\n",
       " ('temps', 0.7658858299255371),\n",
       " ('rentrer', 0.7638633847236633)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeltsv.most_similar('Ulysse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Writing metadata for TensorFlow Projector</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dumped/tensorflow_glove.tsv\", 'w+') as tensors:\n",
    "    with open(\"./dumped/tensorflowmeta_glove.tsv\", 'w+') as metadata:\n",
    "        for word in modeltsv.index2word:\n",
    "            metadata.write(word+'\\n')\n",
    "            vector_row = '\\t'.join(map(str, modeltsv[word]))\n",
    "            tensors.write(vector_row + '\\n')\n",
    "        metadata.close()\n",
    "    tensors.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
